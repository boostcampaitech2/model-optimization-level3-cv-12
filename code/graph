digraph {
	graph [size="32.85,32.85"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140411158505184 [label="
 (32, 6, 1, 1)" fillcolor=darkolivegreen1]
	140411158625552 [label=NativeBatchNormBackward]
	140411158622800 -> 140411158625552
	140411158622800 [label=MkldnnConvolutionBackward]
	140411158462224 -> 140411158622800
	140411158462224 [label=ReluBackward0]
	140411158459920 -> 140411158462224
	140411158459920 [label=NativeBatchNormBackward]
	140411158461520 -> 140411158459920
	140411158461520 [label=MkldnnConvolutionBackward]
	140411158459152 -> 140411158461520
	140411158459152 [label=ViewBackward]
	140411158458576 -> 140411158459152
	140411158458576 [label=MeanBackward1]
	140411158460304 -> 140411158458576
	140411158460304 [label=ViewBackward]
	140411158459344 -> 140411158460304
	140411158459344 [label=NativeBatchNormBackward]
	140411158461136 -> 140411158459344
	140411158461136 [label=MkldnnConvolutionBackward]
	140411158600848 -> 140411158461136
	140411158600848 [label=HardtanhBackward1]
	140411158599760 -> 140411158600848
	140411158599760 [label=NativeBatchNormBackward]
	140411158598672 -> 140411158599760
	140411158598672 [label=MkldnnConvolutionBackward]
	140411158599632 -> 140411158598672
	140411158599632 [label=HardtanhBackward1]
	140411158601360 -> 140411158599632
	140411158601360 [label=NativeBatchNormBackward]
	140411158601488 -> 140411158601360
	140411158601488 [label=MkldnnConvolutionBackward]
	140411158601616 -> 140411158601488
	140411158601616 [label=ReluBackward0]
	140411158601104 -> 140411158601616
	140411158601104 [label=NativeBatchNormBackward]
	140411158598480 -> 140411158601104
	140411158598480 [label=MkldnnConvolutionBackward]
	140411158598736 -> 140411158598480
	140411158598736 [label=ReluBackward0]
	140411158597840 -> 140411158598736
	140411158597840 [label=NativeBatchNormBackward]
	140411158599248 -> 140411158597840
	140411158599248 [label=MkldnnConvolutionBackward]
	140411158601680 -> 140411158599248
	140411158601680 [label=ReluBackward0]
	140411158600464 -> 140411158601680
	140411158600464 [label=NativeBatchNormBackward]
	140411158600656 -> 140411158600464
	140411158600656 [label=MkldnnConvolutionBackward]
	140411158601168 -> 140411158600656
	140411158601168 [label=ReluBackward0]
	140411158600272 -> 140411158601168
	140411158600272 [label=NativeBatchNormBackward]
	140409023414992 -> 140411158600272
	140409023414992 [label=MkldnnConvolutionBackward]
	140409023466768 -> 140409023414992
	140409023466768 [label=ReluBackward0]
	140411158599568 -> 140409023466768
	140411158599568 [label=NativeBatchNormBackward]
	140411158519952 -> 140411158599568
	140411158519952 [label=MkldnnConvolutionBackward]
	140411158520208 -> 140411158519952
	140411158520208 [label=ReluBackward0]
	140411158522128 -> 140411158520208
	140411158522128 [label=NativeBatchNormBackward]
	140411158521616 -> 140411158522128
	140411158521616 [label=MkldnnConvolutionBackward]
	140411158521936 -> 140411158521616
	140411158521936 [label=ReluBackward0]
	140411158522768 -> 140411158521936
	140411158522768 [label=NativeBatchNormBackward]
	140411158522256 -> 140411158522768
	140411158522256 [label=MkldnnConvolutionBackward]
	140411162593040 -> 140411158522256
	140409109442640 [label="model.0.0.conv.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140409109442640 -> 140411162593040
	140411162593040 [label=AccumulateGrad]
	140411162594384 -> 140411158522768
	140409109034560 [label="model.0.0.bn.weight
 (48)" fillcolor=lightblue]
	140409109034560 -> 140411162594384
	140411162594384 [label=AccumulateGrad]
	140411162595152 -> 140411158522768
	140409109447296 [label="model.0.0.bn.bias
 (48)" fillcolor=lightblue]
	140409109447296 -> 140411162595152
	140411162595152 [label=AccumulateGrad]
	140411161964752 -> 140411158521616
	140409023408400 [label="model.0.1.conv.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140409023408400 -> 140411161964752
	140411161964752 [label=AccumulateGrad]
	140411160165456 -> 140411158522128
	140409023406720 [label="model.0.1.bn.weight
 (48)" fillcolor=lightblue]
	140409023406720 -> 140411160165456
	140411160165456 [label=AccumulateGrad]
	140411160162576 -> 140411158522128
	140409023409280 [label="model.0.1.bn.bias
 (48)" fillcolor=lightblue]
	140409023409280 -> 140411160162576
	140411160162576 [label=AccumulateGrad]
	140411160163216 -> 140411158519952
	140409023908112 [label="model.1.conv.weight
 (48, 1, 1, 1)" fillcolor=lightblue]
	140409023908112 -> 140411160163216
	140411160163216 [label=AccumulateGrad]
	140411160163984 -> 140411158599568
	140409023908992 [label="model.1.bn.weight
 (48)" fillcolor=lightblue]
	140409023908992 -> 140411160163984
	140411160163984 [label=AccumulateGrad]
	140411160165200 -> 140411158599568
	140409023906512 [label="model.1.bn.bias
 (48)" fillcolor=lightblue]
	140409023906512 -> 140411160165200
	140411160165200 [label=AccumulateGrad]
	140411160165264 -> 140409023414992
	140409023687888 [label="model.2.0.conv.weight
 (72, 2, 3, 3)" fillcolor=lightblue]
	140409023687888 -> 140411160165264
	140411160165264 [label=AccumulateGrad]
	140411160166032 -> 140411158600272
	140409023736800 [label="model.2.0.bn.weight
 (72)" fillcolor=lightblue]
	140409023736800 -> 140411160166032
	140411160166032 [label=AccumulateGrad]
	140411160166096 -> 140411158600272
	140409023737360 [label="model.2.0.bn.bias
 (72)" fillcolor=lightblue]
	140409023737360 -> 140411160166096
	140411160166096 [label=AccumulateGrad]
	140411158589136 -> 140411158600656
	140409023477232 [label="model.2.1.conv.weight
 (72, 1, 3, 3)" fillcolor=lightblue]
	140409023477232 -> 140411158589136
	140411158589136 [label=AccumulateGrad]
	140411158634896 -> 140411158600464
	140409023476192 [label="model.2.1.bn.weight
 (72)" fillcolor=lightblue]
	140409023476192 -> 140411158634896
	140411158634896 [label=AccumulateGrad]
	140411158636496 -> 140411158600464
	140409023477872 [label="model.2.1.bn.bias
 (72)" fillcolor=lightblue]
	140409023477872 -> 140411158636496
	140411158636496 [label=AccumulateGrad]
	140411158636560 -> 140411158599248
	140409023130112 [label="model.3.conv.weight
 (184, 9, 5, 5)" fillcolor=lightblue]
	140409023130112 -> 140411158636560
	140411158636560 [label=AccumulateGrad]
	140411158427856 -> 140411158597840
	140409023128112 [label="model.3.bn.weight
 (184)" fillcolor=lightblue]
	140409023128112 -> 140411158427856
	140411158427856 [label=AccumulateGrad]
	140411158428624 -> 140411158597840
	140409023129152 [label="model.3.bn.bias
 (184)" fillcolor=lightblue]
	140409023129152 -> 140411158428624
	140411158428624 [label=AccumulateGrad]
	140411158428816 -> 140411158598480
	140409023128272 [label="model.4.conv.weight
 (144, 184, 3, 3)" fillcolor=lightblue]
	140409023128272 -> 140411158428816
	140411158428816 [label=AccumulateGrad]
	140411351224784 -> 140411158601104
	140409023128752 [label="model.4.bn.weight
 (144)" fillcolor=lightblue]
	140409023128752 -> 140411351224784
	140411351224784 [label=AccumulateGrad]
	140411351226704 -> 140411158601104
	140409023128832 [label="model.4.bn.bias
 (144)" fillcolor=lightblue]
	140409023128832 -> 140411351226704
	140411351226704 [label=AccumulateGrad]
	140411158486544 -> 140411158601488
	140409023129632 [label="model.5.0.conv.0.0.weight
 (864, 144, 1, 1)" fillcolor=lightblue]
	140409023129632 -> 140411158486544
	140411158486544 [label=AccumulateGrad]
	140411158527568 -> 140411158601360
	140409023128432 [label="model.5.0.conv.0.1.weight
 (864)" fillcolor=lightblue]
	140409023128432 -> 140411158527568
	140411158527568 [label=AccumulateGrad]
	140411158525584 -> 140411158601360
	140409023129472 [label="model.5.0.conv.0.1.bias
 (864)" fillcolor=lightblue]
	140409023129472 -> 140411158525584
	140411158525584 [label=AccumulateGrad]
	140411158625296 -> 140411158598672
	140409023129312 [label="model.5.0.conv.1.0.weight
 (864, 1, 3, 3)" fillcolor=lightblue]
	140409023129312 -> 140411158625296
	140411158625296 [label=AccumulateGrad]
	140411158622992 -> 140411158599760
	140409023129792 [label="model.5.0.conv.1.1.weight
 (864)" fillcolor=lightblue]
	140409023129792 -> 140411158622992
	140411158622992 [label=AccumulateGrad]
	140411158623056 -> 140411158599760
	140409023130432 [label="model.5.0.conv.1.1.bias
 (864)" fillcolor=lightblue]
	140409023130432 -> 140411158623056
	140411158623056 [label=AccumulateGrad]
	140411158622288 -> 140411158461136
	140409023131552 [label="model.5.0.conv.2.weight
 (40, 864, 1, 1)" fillcolor=lightblue]
	140409023131552 -> 140411158622288
	140411158622288 [label=AccumulateGrad]
	140411158625040 -> 140411158459344
	140409023131152 [label="model.5.0.conv.3.weight
 (40)" fillcolor=lightblue]
	140409023131152 -> 140411158625040
	140411158625040 [label=AccumulateGrad]
	140411158626064 -> 140411158459344
	140409023130192 [label="model.5.0.conv.3.bias
 (40)" fillcolor=lightblue]
	140409023130192 -> 140411158626064
	140411158626064 [label=AccumulateGrad]
	140411158624336 -> 140411158461520
	140409023128992 [label="model.7.conv.weight
 (768, 40, 1, 1)" fillcolor=lightblue]
	140409023128992 -> 140411158624336
	140411158624336 [label=AccumulateGrad]
	140411158623888 -> 140411158459920
	140409023128352 [label="model.7.bn.weight
 (768)" fillcolor=lightblue]
	140409023128352 -> 140411158623888
	140411158623888 [label=AccumulateGrad]
	140411158622672 -> 140411158459920
	140409023127792 [label="model.7.bn.bias
 (768)" fillcolor=lightblue]
	140409023127792 -> 140411158622672
	140411158622672 [label=AccumulateGrad]
	140411158622544 -> 140411158622800
	140409023130272 [label="model.8.conv.weight
 (6, 768, 1, 1)" fillcolor=lightblue]
	140409023130272 -> 140411158622544
	140411158622544 [label=AccumulateGrad]
	140411158625360 -> 140411158625552
	140409023128192 [label="model.8.bn.weight
 (6)" fillcolor=lightblue]
	140409023128192 -> 140411158625360
	140411158625360 [label=AccumulateGrad]
	140411158624208 -> 140411158625552
	140409023763152 [label="model.8.bn.bias
 (6)" fillcolor=lightblue]
	140409023763152 -> 140411158624208
	140411158624208 [label=AccumulateGrad]
	140411158625552 -> 140411158505184
}
