idx |   n |     params |          module |            arguments |   in_channel |   out_channel
----------------------------------------------------------------------------------------------
  0 |   2 |      2,800 |            Conv | [16, 3, 1, None, 1, 'ReLU'] |            3           16
  1 |   2 |      4,384 | InvertedResidualv2 |           [16, 3, 2] |           16           16
  2 |   3 |      7,696 | InvertedResidualv2 |           [32, 2, 2] |           16           24
  3 |   1 |      2,912 |            Conv | [144, 1, 2, None, 1, 'Hardswish'] |           24          112
  4 |   3 |     21,680 | InvertedResidualv2 |           [96, 1, 2] |          112           72
  5 |   2 |     57,328 | InvertedResidualv3 | [5, 1.3, 152, 0, 1, 1] |           72          112
  6 |   1 |     10,944 |            Conv |          [128, 1, 1] |          112           96
  7 |   1 |          0 |   GlobalAvgPool |                   [] |           96           96
  8 |   1 |        588 |       FixedConv | [6, 1, 1, None, 1, None] |           96            6
Model Summary: 133 layers, 108,332 parameters, 108,332 gradients
tune.py:464: FutureWarning: MOTPESampler has been deprecated in v2.9.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.9.0.
  sampler = optuna.samplers.MOTPESampler()
[32m[I 2021-11-26 00:08:27,651][39m A new study created in memory with name: automl101
---------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------
Name                               Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     CUDA total %     CUDA total       CUDA time avg    Number of Calls  Input Shapes
---------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------

























Train: [001] Loss: 1.589, Acc: 34.75% F1(macro): 0.15: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.25it/s]












 Val:       Loss: 1.494, Acc: 41.16% F1(macro): 0.18: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.31it/s]
  0%|                                                                                                                               | 0/488 [00:00<?, ?it/s]
conv2d                             0.10%            16.499us         2.13%            358.715us        358.715us        0.61%            358.400us        358.400us        1                []
convolution                        0.07%            11.634us         2.04%            342.216us        342.216us        0.58%            342.016us        342.016us        1                []
_convolution                       0.36%            60.161us         1.97%            330.582us        330.582us        0.56%            329.728us        329.728us        1                []
size                               0.03%            4.556us          0.03%            4.556us          4.556us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.790us          0.02%            3.790us          3.790us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.865us          0.02%            3.865us          3.865us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.414us          0.02%            3.414us          3.414us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.347us          0.02%            3.347us          3.347us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.518us          0.02%            3.518us          3.518us          0.01%            3.072us          3.072us          1                []
contiguous                         0.02%            4.134us          0.02%            4.134us          4.134us          0.01%            4.096us          4.096us          1                []
cudnn_convolution                  0.93%            156.779us        1.45%            243.797us        243.797us        0.42%            243.712us        243.712us        1                []
empty                              0.05%            8.228us          0.05%            8.228us          8.228us          0.01%            8.192us          8.192us          1                []
contiguous                         0.02%            3.870us          0.02%            3.870us          3.870us          0.01%            4.096us          4.096us          1                []
resize_                            0.03%            4.371us          0.03%            4.371us          4.371us          0.01%            4.096us          4.096us          1                []
contiguous                         0.02%            3.568us          0.02%            3.568us          3.568us          0.01%            3.104us          3.104us          1                []
resize_                            0.02%            3.675us          0.02%            3.675us          3.675us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.710us          0.02%            3.710us          3.710us          0.01%            4.096us          4.096us          1                []
stride                             0.03%            4.693us          0.03%            4.693us          4.693us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.767us          0.02%            3.767us          3.767us          0.01%            4.064us          4.064us          1                []
size                               0.02%            3.520us          0.02%            3.520us          3.520us          0.01%            3.072us          3.072us          1                []
stride                             0.02%            3.519us          0.02%            3.519us          3.519us          0.01%            3.072us          3.072us          1                []
size                               0.02%            4.014us          0.02%            4.014us          4.014us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.319us          0.02%            3.319us          3.319us          0.01%            3.104us          3.104us          1                []
stride                             0.02%            3.296us          0.02%            3.296us          3.296us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.494us          0.02%            3.494us          3.494us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.581us          0.02%            3.581us          3.581us          0.01%            3.072us          3.072us          1                []
stride                             0.02%            3.303us          0.02%            3.303us          3.303us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.507us          0.02%            3.507us          3.507us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.645us          0.02%            3.645us          3.645us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.571us          0.02%            3.571us          3.571us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.434us          0.02%            3.434us          3.434us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.360us          0.02%            3.360us          3.360us          0.01%            3.072us          3.072us          1                []
empty                              0.03%            5.573us          0.03%            5.573us          5.573us          0.01%            5.120us          5.120us          1                []
batch_norm                         0.07%            12.404us         0.99%            167.186us        167.186us        0.29%            166.912us        166.912us        1                []
_batch_norm_impl_index             0.25%            41.342us         0.92%            154.782us        154.782us        0.27%            155.648us        155.648us        1                []
size                               0.02%            3.979us          0.02%            3.979us          3.979us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.412us          0.02%            3.412us          3.412us          0.01%            4.096us          4.096us          1                []
contiguous                         0.02%            3.894us          0.02%            3.894us          3.894us          0.01%            4.096us          4.096us          1                []
contiguous                         0.02%            3.683us          0.02%            3.683us          3.683us          0.01%            3.072us          3.072us          1                []
contiguous                         0.02%            3.809us          0.02%            3.809us          3.809us          0.01%            4.096us          4.096us          1                []
contiguous                         0.02%            3.787us          0.02%            3.787us          3.787us          0.01%            4.096us          4.096us          1                []
contiguous                         0.02%            3.537us          0.02%            3.537us          3.537us          0.01%            3.072us          3.072us          1                []
cudnn_batch_norm                   0.34%            56.584us         0.52%            87.339us         87.339us         0.15%            88.064us         88.064us         1                []
size                               0.02%            4.074us          0.02%            4.074us          4.074us          0.01%            4.096us          4.096us          1                []
empty_like                         0.05%            9.231us          0.09%            15.684us         15.684us         0.03%            15.360us         15.360us         1                []
empty                              0.04%            6.453us          0.04%            6.453us          6.453us          0.01%            6.144us          6.144us          1                []
view                               0.04%            6.743us          0.04%            6.743us          6.743us          0.01%            6.144us          6.144us          1                []
empty                              0.03%            4.254us          0.03%            4.254us          4.254us          0.01%            4.096us          4.096us          1                []
relu                               0.12%            20.956us         0.29%            48.531us         48.531us         0.08%            48.128us         48.128us         1                []
threshold                          0.12%            20.905us         0.16%            27.575us         27.575us         0.05%            28.672us         28.672us         1                []
empty                              0.04%            6.670us          0.04%            6.670us          6.670us          0.01%            7.168us          7.168us          1                []
conv2d                             0.06%            9.560us          1.77%            297.649us        297.649us        0.51%            296.960us        296.960us        1                []
convolution                        0.06%            9.336us          1.71%            288.089us        288.089us        0.49%            287.744us        287.744us        1                []
_convolution                       0.24%            40.676us         1.66%            278.753us        278.753us        0.48%            278.528us        278.528us        1                []
size                               0.02%            4.153us          0.02%            4.153us          4.153us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.621us          0.02%            3.621us          3.621us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.631us          0.02%            3.631us          3.631us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.364us          0.02%            3.364us          3.364us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.540us          0.02%            3.540us          3.540us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.409us          0.02%            3.409us          3.409us          0.01%            3.072us          3.072us          1                []
contiguous                         0.02%            3.802us          0.02%            3.802us          3.802us          0.01%            4.096us          4.096us          1                []
cudnn_convolution                  0.78%            130.515us        1.26%            212.557us        212.557us        0.37%            214.016us        214.016us        1                []
empty                              0.04%            6.127us          0.04%            6.127us          6.127us          0.01%            7.168us          7.168us          1                []
contiguous                         0.02%            3.856us          0.02%            3.856us          3.856us          0.01%            4.096us          4.096us          1                []
resize_                            0.02%            4.027us          0.02%            4.027us          4.027us          0.01%            4.096us          4.096us          1                []
contiguous                         0.02%            3.523us          0.02%            3.523us          3.523us          0.01%            3.072us          3.072us          1                []
resize_                            0.02%            3.952us          0.02%            3.952us          3.952us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.586us          0.02%            3.586us          3.586us          0.01%            4.096us          4.096us          1                []
stride                             0.02%            3.539us          0.02%            3.539us          3.539us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.354us          0.02%            3.354us          3.354us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.556us          0.02%            3.556us          3.556us          0.01%            3.072us          3.072us          1                []
stride                             0.02%            3.312us          0.02%            3.312us          3.312us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.440us          0.02%            3.440us          3.440us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.293us          0.02%            3.293us          3.293us          0.01%            3.072us          3.072us          1                []
stride                             0.02%            3.426us          0.02%            3.426us          3.426us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.342us          0.02%            3.342us          3.342us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.340us          0.02%            3.340us          3.340us          0.01%            3.072us          3.072us          1                []
stride                             0.02%            3.484us          0.02%            3.484us          3.484us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.445us          0.02%            3.445us          3.445us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.415us          0.02%            3.415us          3.415us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.339us          0.02%            3.339us          3.339us          0.01%            3.072us          3.072us          1                []
size                               0.02%            3.348us          0.02%            3.348us          3.348us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.541us          0.02%            3.541us          3.541us          0.01%            4.096us          4.096us          1                []
empty                              0.03%            5.797us          0.03%            5.797us          5.797us          0.01%            6.144us          6.144us          1                []
batch_norm                         0.06%            10.093us         0.87%            145.386us        145.386us        0.25%            144.384us        144.384us        1                []
_batch_norm_impl_index             0.22%            36.931us         0.81%            135.293us        135.293us        0.23%            135.168us        135.168us        1                []
size                               0.02%            3.897us          0.02%            3.897us          3.897us          0.01%            4.096us          4.096us          1                []
size                               0.02%            3.306us          0.02%            3.306us          3.306us          0.01%            3.072us          3.072us          1                []
contiguous                         0.02%            3.851us          0.02%            3.851us          3.851us          0.01%            4.096us          4.096us          1                []
contiguous                         0.03%            4.426us          0.03%            4.426us          4.426us          0.01%            4.096us          4.096us          1                []
contiguous                         0.02%            3.447us          0.02%            3.447us          3.447us          0.01%            4.096us          4.096us          1                []
contiguous                         0.02%            3.480us          0.02%            3.480us          3.480us          0.01%            4.096us          4.096us          1                []
contiguous                         0.02%            3.521us          0.02%            3.521us          3.521us          0.01%            4.096us          4.096us          1                []
cudnn_batch_norm                   0.27%            44.701us         0.43%            72.434us         72.434us         0.12%            71.680us         71.680us         1                []
size                               0.02%            3.584us          0.02%            3.584us          3.584us          0.01%            3.072us          3.072us          1                []
empty_like                         0.05%            8.541us          0.09%            14.663us         14.663us         0.02%            14.336us         14.336us         1                []
empty                              0.04%            6.122us          0.04%            6.122us          6.122us          0.01%            6.144us          6.144us          1                []
view                               0.03%            5.340us          0.03%            5.340us          5.340us          0.01%            5.120us          5.120us          1                []
empty                              0.02%            4.146us          0.02%            4.146us          4.146us          0.01%            4.096us          4.096us          1                []
relu                               0.10%            17.336us         0.24%            40.812us         40.812us         0.07%            40.960us         40.960us         1                []
---------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------------------------------------
Self CPU time total: 16.805ms
CUDA time total: 58.547ms
measured time(ms) 3.544473568598429
layer                                     name  gradient   parameters                shape         mu      sigma
    0                    model.0.0.conv.weight      True          432        [16, 3, 3, 3]  -0.000537      0.117
    1                      model.0.0.bn.weight      True           16                 [16]          1          0
    2                        model.0.0.bn.bias      True           16                 [16]          0          0
    3                    model.0.1.conv.weight      True         2304       [16, 16, 3, 3]   -0.00243     0.0481
    4                      model.0.1.bn.weight      True           16                 [16]          1          0
    5                        model.0.1.bn.bias      True           16                 [16]          0          0
    6                model.1.0.conv.0.0.weight      True          768       [48, 16, 1, 1]   -0.00269      0.145
    7                model.1.0.conv.0.1.weight      True           48                 [48]          1          0
    8                  model.1.0.conv.0.1.bias      True           48                 [48]          0          0
    9                model.1.0.conv.1.0.weight      True          432        [48, 1, 3, 3]     0.0114      0.189
   10                model.1.0.conv.1.1.weight      True           48                 [48]          1          0
   11                  model.1.0.conv.1.1.bias      True           48                 [48]          0          0
   12                  model.1.0.conv.2.weight      True          768       [16, 48, 1, 1]    0.00364     0.0834
   13                  model.1.0.conv.3.weight      True           16                 [16]          1          0
   14                    model.1.0.conv.3.bias      True           16                 [16]          0          0
   15                model.1.1.conv.0.0.weight      True          768       [48, 16, 1, 1]   -0.00333      0.143
   16                model.1.1.conv.0.1.weight      True           48                 [48]          1          0
   17                  model.1.1.conv.0.1.bias      True           48                 [48]          0          0
   18                model.1.1.conv.1.0.weight      True          432        [48, 1, 3, 3]   -0.00685       0.19
   19                model.1.1.conv.1.1.weight      True           48                 [48]          1          0
   20                  model.1.1.conv.1.1.bias      True           48                 [48]          0          0
   21                  model.1.1.conv.2.weight      True          768       [16, 48, 1, 1]   7.27e-05     0.0827
   22                  model.1.1.conv.3.weight      True           16                 [16]          1          0
   23                    model.1.1.conv.3.bias      True           16                 [16]          0          0
   24                model.2.0.conv.0.0.weight      True          512       [32, 16, 1, 1]    0.00143      0.141
   25                model.2.0.conv.0.1.weight      True           32                 [32]          1          0
   26                  model.2.0.conv.0.1.bias      True           32                 [32]          0          0
   27                model.2.0.conv.1.0.weight      True          288        [32, 1, 3, 3]    0.00327      0.195
   28                model.2.0.conv.1.1.weight      True           32                 [32]          1          0
   29                  model.2.0.conv.1.1.bias      True           32                 [32]          0          0
   30                  model.2.0.conv.2.weight      True          768       [24, 32, 1, 1]   -0.00121      0.103
   31                  model.2.0.conv.3.weight      True           24                 [24]          1          0
   32                    model.2.0.conv.3.bias      True           24                 [24]          0          0
   33                model.2.1.conv.0.0.weight      True         1152       [48, 24, 1, 1]   -0.00239      0.119
   34                model.2.1.conv.0.1.weight      True           48                 [48]          1          0
   35                  model.2.1.conv.0.1.bias      True           48                 [48]          0          0
   36                model.2.1.conv.1.0.weight      True          432        [48, 1, 3, 3]    0.00663      0.189
   37                model.2.1.conv.1.1.weight      True           48                 [48]          1          0
   38                  model.2.1.conv.1.1.bias      True           48                 [48]          0          0
   39                  model.2.1.conv.2.weight      True         1152       [24, 48, 1, 1]  -0.000123     0.0832
   40                  model.2.1.conv.3.weight      True           24                 [24]          1          0
   41                    model.2.1.conv.3.bias      True           24                 [24]          0          0
   42                model.2.2.conv.0.0.weight      True         1152       [48, 24, 1, 1]     0.0047       0.12
   43                model.2.2.conv.0.1.weight      True           48                 [48]          1          0
   44                  model.2.2.conv.0.1.bias      True           48                 [48]          0          0
   45                model.2.2.conv.1.0.weight      True          432        [48, 1, 3, 3]    0.00157      0.194
   46                model.2.2.conv.1.1.weight      True           48                 [48]          1          0
   47                  model.2.2.conv.1.1.bias      True           48                 [48]          0          0
   48                  model.2.2.conv.2.weight      True         1152       [24, 48, 1, 1]  -0.000201     0.0831
   49                  model.2.2.conv.3.weight      True           24                 [24]          1          0
   50                    model.2.2.conv.3.bias      True           24                 [24]          0          0
   51                      model.3.conv.weight      True         2688      [112, 24, 1, 1]    -0.0013      0.118
   52                        model.3.bn.weight      True          112                [112]          1          0
   53                          model.3.bn.bias      True          112                [112]          0          0
   54                model.4.0.conv.0.0.weight      True         1008       [112, 1, 3, 3]   -0.00215      0.196
   55                model.4.0.conv.0.1.weight      True          112                [112]          1          0
   56                  model.4.0.conv.0.1.bias      True          112                [112]          0          0
   57                  model.4.0.conv.1.weight      True         8064      [72, 112, 1, 1]  -0.000793     0.0543
   58                  model.4.0.conv.2.weight      True           72                 [72]          1          0
   59                    model.4.0.conv.2.bias      True           72                 [72]          0          0
   60                model.4.1.conv.0.0.weight      True          648        [72, 1, 3, 3]    -0.0068      0.191
   61                model.4.1.conv.0.1.weight      True           72                 [72]          1          0
   62                  model.4.1.conv.0.1.bias      True           72                 [72]          0          0
   63                  model.4.1.conv.1.weight      True         5184       [72, 72, 1, 1]   -0.00116     0.0685
   64                  model.4.1.conv.2.weight      True           72                 [72]          1          0
   65                    model.4.1.conv.2.bias      True           72                 [72]          0          0
   66                model.4.2.conv.0.0.weight      True          648        [72, 1, 3, 3]    0.00224      0.191
   67                model.4.2.conv.0.1.weight      True           72                 [72]          1          0
   68                  model.4.2.conv.0.1.bias      True           72                 [72]          0          0
   69                  model.4.2.conv.1.weight      True         5184       [72, 72, 1, 1]   3.84e-05     0.0678
   70                  model.4.2.conv.2.weight      True           72                 [72]          1          0
   71                    model.4.2.conv.2.bias      True           72                 [72]          0          0
   72                  model.5.0.conv.0.weight      True         6912       [96, 72, 1, 1]   -0.00108     0.0685
   73                  model.5.0.conv.1.weight      True           96                 [96]          1          0
   74                    model.5.0.conv.1.bias      True           96                 [96]          0          0
   75                  model.5.0.conv.3.weight      True         2400        [96, 1, 5, 5]   -0.00452      0.115
   76                  model.5.0.conv.4.weight      True           96                 [96]          1          0
   77                    model.5.0.conv.4.bias      True           96                 [96]          0          0
   78                  model.5.0.conv.7.weight      True        10752      [112, 96, 1, 1]    0.00146     0.0585
   79                  model.5.0.conv.8.weight      True          112                [112]          1          0
   80                    model.5.0.conv.8.bias      True          112                [112]          0          0
   81                  model.5.1.conv.0.weight      True        16128     [144, 112, 1, 1]  -0.000485     0.0547
   82                  model.5.1.conv.1.weight      True          144                [144]          1          0
   83                    model.5.1.conv.1.bias      True          144                [144]          0          0
   84                  model.5.1.conv.3.weight      True         3600       [144, 1, 5, 5]  -0.000536      0.115
   85                  model.5.1.conv.4.weight      True          144                [144]          1          0
   86                    model.5.1.conv.4.bias      True          144                [144]          0          0
   87                  model.5.1.conv.7.weight      True        16128     [112, 144, 1, 1]   6.94e-05     0.0481
   88                  model.5.1.conv.8.weight      True          112                [112]          1          0
   89                    model.5.1.conv.8.bias      True          112                [112]          0          0
   90                      model.6.conv.weight      True        10752      [96, 112, 1, 1]  -0.000349     0.0547
   91                        model.6.bn.weight      True           96                 [96]          1          0
   92                          model.6.bn.bias      True           96                 [96]          0          0
   93                      model.8.conv.weight      True          576        [6, 96, 1, 1]    0.00191     0.0583
   94                        model.8.bn.weight      True            6                  [6]          1          0
   95                          model.8.bn.bias      True            6                  [6]          0          0
Model Summary: 134 layers, 108,332 parameters, 108,332 gradients


























Train: [002] Loss: 1.555, Acc: 36.80% F1(macro): 0.16: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.10it/s]












 Val:       Loss: 1.510, Acc: 38.17% F1(macro): 0.16: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.29it/s]


























Train: [003] Loss: 1.545, Acc: 37.39% F1(macro): 0.17: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.14it/s]












 Val:       Loss: 1.452, Acc: 43.05% F1(macro): 0.23: : 184it [00:24,  5.26it/s]
 Val:       Loss: 1.458, Acc: 42.85% F1(macro): 0.23: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.35it/s]

























Train: [004] Loss: 1.529, Acc: 39.40% F1(macro): 0.17: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.30it/s]












 Val:       Loss: 1.477, Acc: 42.20% F1(macro): 0.17: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.35it/s]

























Train: [005] Loss: 1.519, Acc: 40.60% F1(macro): 0.18: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.38it/s]












 Val:       Loss: 1.463, Acc: 44.85% F1(macro): 0.21: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.35it/s]


























Train: [006] Loss: 1.502, Acc: 42.07% F1(macro): 0.19: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.28it/s]












 Val:       Loss: 1.408, Acc: 46.04% F1(macro): 0.25: : 183it [00:24,  4.75it/s]
 Val:       Loss: 1.413, Acc: 45.96% F1(macro): 0.25: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.32it/s]


























Train: [007] Loss: 1.485, Acc: 43.17% F1(macro): 0.20: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.09it/s]














 Val:       Loss: 1.365, Acc: 48.21% F1(macro): 0.24: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:30<00:00,  5.37it/s]

























Train: [008] Loss: 1.476, Acc: 43.63% F1(macro): 0.20: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.22it/s]













 Val:       Loss: 1.360, Acc: 49.15% F1(macro): 0.26: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.34it/s]
Model saved. Current best test f1: 0.256

























Train: [009] Loss: 1.465, Acc: 44.63% F1(macro): 0.20: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.30it/s]












 Val:       Loss: 1.344, Acc: 49.26% F1(macro): 0.26: : 182it [00:25,  5.31it/s]
 Val:       Loss: 1.348, Acc: 48.97% F1(macro): 0.26: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.30it/s]

























Train: [010] Loss: 1.458, Acc: 44.45% F1(macro): 0.21: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.32it/s]












 Val:       Loss: 1.351, Acc: 48.92% F1(macro): 0.27: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.33it/s]
  0%|                                                                                                                               | 0/488 [00:00<?, ?it/s]


























Train: [011] Loss: 1.450, Acc: 44.97% F1(macro): 0.21: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.34it/s]












 Val:       Loss: 1.340, Acc: 50.18% F1(macro): 0.28: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.32it/s]
Model saved. Current best test f1: 0.277

























Train: [012] Loss: 1.437, Acc: 45.48% F1(macro): 0.22: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.21it/s]













 Val:       Loss: 1.316, Acc: 50.39% F1(macro): 0.31: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:26<00:00,  6.26it/s]
Model saved. Current best test f1: 0.307

























Train: [013] Loss: 1.426, Acc: 45.86% F1(macro): 0.23: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.32it/s]












 Val:       Loss: 1.308, Acc: 51.16% F1(macro): 0.29: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.31it/s]

























Train: [014] Loss: 1.422, Acc: 46.56% F1(macro): 0.24: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.22it/s]












 Val:       Loss: 1.312, Acc: 51.22% F1(macro): 0.35: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.29it/s]
  0%|                                                                                                                               | 0/488 [00:00<?, ?it/s]


























Train: [015] Loss: 1.413, Acc: 46.56% F1(macro): 0.24: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.31it/s]












 Val:       Loss: 1.310, Acc: 50.03% F1(macro): 0.31: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.32it/s]

























Train: [016] Loss: 1.403, Acc: 46.51% F1(macro): 0.24: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.29it/s]












 Val:       Loss: 1.273, Acc: 51.97% F1(macro): 0.35: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:26<00:00,  6.25it/s]


























Train: [017] Loss: 1.400, Acc: 47.27% F1(macro): 0.26: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.13it/s]












 Val:       Loss: 1.271, Acc: 52.62% F1(macro): 0.34: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.30it/s]

























Train: [018] Loss: 1.394, Acc: 47.50% F1(macro): 0.26: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.31it/s]













 Val:       Loss: 1.252, Acc: 53.44% F1(macro): 0.36: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.30it/s]
Model saved. Current best test f1: 0.356


























Train: [019] Loss: 1.386, Acc: 47.74% F1(macro): 0.27: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:54<00:00,  9.00it/s]












 Val:       Loss: 1.243, Acc: 52.93% F1(macro): 0.34: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.31it/s]

























Train: [020] Loss: 1.387, Acc: 47.53% F1(macro): 0.26: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.17it/s]












 Val:       Loss: 1.278, Acc: 51.47% F1(macro): 0.35: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.31it/s]


























Train: [021] Loss: 1.379, Acc: 47.88% F1(macro): 0.26: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.28it/s]












 Val:       Loss: 1.249, Acc: 53.38% F1(macro): 0.37: : 182it [00:25,  4.73it/s]
 Val:       Loss: 1.253, Acc: 53.21% F1(macro): 0.37: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.30it/s]


























Train: [022] Loss: 1.365, Acc: 48.49% F1(macro): 0.28: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.15it/s]












 Val:       Loss: 1.250, Acc: 52.87% F1(macro): 0.37: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.32it/s]

























Train: [023] Loss: 1.355, Acc: 49.43% F1(macro): 0.29: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.23it/s]












 Val:       Loss: 1.203, Acc: 55.47% F1(macro): 0.38: : 182it [00:24,  5.33it/s]
 Val:       Loss: 1.214, Acc: 54.90% F1(macro): 0.38: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.34it/s]

























Train: [024] Loss: 1.363, Acc: 48.50% F1(macro): 0.28: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.34it/s]













 Val:       Loss: 1.250, Acc: 53.35% F1(macro): 0.38: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.28it/s]

























Train: [025] Loss: 1.353, Acc: 49.03% F1(macro): 0.29: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.21it/s]












 Val:       Loss: 1.204, Acc: 55.63% F1(macro): 0.42: : 182it [00:24,  5.29it/s]
 Val:       Loss: 1.209, Acc: 55.34% F1(macro): 0.42: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.32it/s]

























Train: [026] Loss: 1.347, Acc: 49.05% F1(macro): 0.29: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.23it/s]













 Val:       Loss: 1.207, Acc: 55.21% F1(macro): 0.41: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:26<00:00,  6.23it/s]

























Train: [027] Loss: 1.351, Acc: 49.23% F1(macro): 0.29: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.18it/s]













 Val:       Loss: 1.205, Acc: 55.15% F1(macro): 0.40: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.29it/s]

























Train: [028] Loss: 1.349, Acc: 49.23% F1(macro): 0.29: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.20it/s]












 Val:       Loss: 1.199, Acc: 55.46% F1(macro): 0.41: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.32it/s]

























Train: [029] Loss: 1.337, Acc: 49.83% F1(macro): 0.30: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.30it/s]












 Val:       Loss: 1.201, Acc: 55.63% F1(macro): 0.39: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.34it/s]


























Train: [030] Loss: 1.328, Acc: 50.22% F1(macro): 0.31: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.16it/s]












 Val:       Loss: 1.152, Acc: 56.79% F1(macro): 0.42: : 177it [00:24,  4.97it/s]
 Val:       Loss: 1.175, Acc: 55.61% F1(macro): 0.42: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.32it/s]





























Train: [031] Loss: 1.325, Acc: 50.26% F1(macro): 0.31: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:59<00:00,  8.26it/s]












 Val:       Loss: 1.159, Acc: 57.29% F1(macro): 0.44: : 181it [00:25,  5.08it/s]
 Val:       Loss: 1.164, Acc: 56.90% F1(macro): 0.44: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:26<00:00,  6.22it/s]


























Train: [032] Loss: 1.315, Acc: 50.59% F1(macro): 0.33: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.09it/s]












 Val:       Loss: 1.155, Acc: 56.82% F1(macro): 0.43: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:26<00:00,  6.21it/s]

























Train: [033] Loss: 1.320, Acc: 50.26% F1(macro): 0.31: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.28it/s]













 Val:       Loss: 1.186, Acc: 55.71% F1(macro): 0.43: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.30it/s]

























Train: [034] Loss: 1.306, Acc: 50.95% F1(macro): 0.32: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.19it/s]













 Val:       Loss: 1.138, Acc: 57.65% F1(macro): 0.45: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:26<00:00,  6.26it/s]
Model saved. Current best test f1: 0.446

























Train: [035] Loss: 1.311, Acc: 51.04% F1(macro): 0.32: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.33it/s]












 Val:       Loss: 1.136, Acc: 58.27% F1(macro): 0.45: : 182it [00:25,  5.38it/s]
 Val:       Loss: 1.139, Acc: 58.01% F1(macro): 0.45: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:26<00:00,  6.26it/s]


























Train: [036] Loss: 1.307, Acc: 51.06% F1(macro): 0.32: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:54<00:00,  9.03it/s]












 Val:       Loss: 1.147, Acc: 57.53% F1(macro): 0.42: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.31it/s]


























Train: [037] Loss: 1.295, Acc: 51.25% F1(macro): 0.33: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.25it/s]












 Val:       Loss: 1.125, Acc: 58.63% F1(macro): 0.45: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.30it/s]

























Train: [038] Loss: 1.292, Acc: 51.69% F1(macro): 0.34: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.34it/s]












 Val:       Loss: 1.121, Acc: 58.72% F1(macro): 0.46: : 183it [00:24,  5.35it/s]
 Val:       Loss: 1.121, Acc: 58.61% F1(macro): 0.46: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.36it/s]

























Train: [039] Loss: 1.277, Acc: 51.86% F1(macro): 0.34: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.30it/s]












 Val:       Loss: 1.122, Acc: 58.11% F1(macro): 0.44: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.31it/s]

























Train: [040] Loss: 1.282, Acc: 52.13% F1(macro): 0.34: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.26it/s]













 Val:       Loss: 1.099, Acc: 59.47% F1(macro): 0.47: : 183it [00:24,  5.21it/s]
 Val:       Loss: 1.100, Acc: 59.34% F1(macro): 0.48: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.33it/s]


























Train: [041] Loss: 1.268, Acc: 52.65% F1(macro): 0.35: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:54<00:00,  9.01it/s]












 Val:       Loss: 1.099, Acc: 59.12% F1(macro): 0.47: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:26<00:00,  6.26it/s]


























Train: [042] Loss: 1.271, Acc: 52.79% F1(macro): 0.35: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.21it/s]












 Val:       Loss: 1.096, Acc: 59.59% F1(macro): 0.47: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.33it/s]

























Train: [043] Loss: 1.261, Acc: 52.59% F1(macro): 0.35: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.13it/s]












 Val:       Loss: 1.096, Acc: 59.16% F1(macro): 0.47: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.27it/s]


























Train: [044] Loss: 1.251, Acc: 53.11% F1(macro): 0.36: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.25it/s]












 Val:       Loss: 1.087, Acc: 59.55% F1(macro): 0.49: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:26<00:00,  6.26it/s]
  0%|                                                                                                                               | 0/488 [00:00<?, ?it/s]


























Train: [045] Loss: 1.254, Acc: 52.87% F1(macro): 0.36: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.28it/s]












 Val:       Loss: 1.077, Acc: 60.28% F1(macro): 0.49: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.27it/s]

























Train: [046] Loss: 1.244, Acc: 53.79% F1(macro): 0.37: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:53<00:00,  9.17it/s]












 Val:       Loss: 1.077, Acc: 59.95% F1(macro): 0.49: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.33it/s]


























Train: [047] Loss: 1.242, Acc: 53.53% F1(macro): 0.37: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.28it/s]












 Val:       Loss: 1.075, Acc: 60.18% F1(macro): 0.49: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.31it/s]
Model saved. Current best test f1: 0.493

























Train: [048] Loss: 1.242, Acc: 53.80% F1(macro): 0.37: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.26it/s]












 Val:       Loss: 1.076, Acc: 60.35% F1(macro): 0.49: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.35it/s]

























Train: [049] Loss: 1.240, Acc: 53.34% F1(macro): 0.37: 100%|██████████████████████████████████████████████████████████████| 488/488 [00:52<00:00,  9.26it/s]
 Val:       Loss: 1.863, Acc: 31.77% F1(macro): 0.08:   5%|███▏                                                             | 8/163 [00:01<00:28,  5.35it/s]
 Val:       Loss: 1.543, Acc: 42.58% F1(macro): 0.18:  14%|█████████                                                       | 23/163 [00:03<00:26,  5.33it/s]
 Val:       Loss: 1.124, Acc: 61.46% F1(macro): 0.21:  27%|█████████████████▎                                              | 44/163 [00:06<00:15,  7.64it/s]
 Val:       Loss: 0.962, Acc: 68.39% F1(macro): 0.22:  40%|█████████████████████████▌                                      | 65/163 [00:08<00:11,  8.36it/s]
 Val:       Loss: 1.005, Acc: 66.56% F1(macro): 0.27:  50%|████████████████████████████████▏                               | 82/163 [00:09<00:08,  9.01it/s]
 Val:       Loss: 1.134, Acc: 58.73% F1(macro): 0.32:  61%|██████████████████████████████████████▊                         | 99/163 [00:12<00:07,  8.55it/s]
 Val:       Loss: 1.197, Acc: 53.79% F1(macro): 0.32:  71%|████████████████████████████████████████████▊                  | 116/163 [00:14<00:05,  8.83it/s]
 Val:       Loss: 1.162, Acc: 55.55% F1(macro): 0.39:  80%|██████████████████████████████████████████████████▋            | 131/163 [00:16<00:04,  6.92it/s]
 Val:       Loss: 1.125, Acc: 57.52% F1(macro): 0.41:  87%|██████████████████████████████████████████████████████▍        | 141/163 [00:17<00:03,  5.91it/s]
 Val:       Loss: 1.080, Acc: 59.90% F1(macro): 0.42:  96%|████████████████████████████████████████████████████████████▋  | 157/163 [00:20<00:00,  6.03it/s]
 Val:       Loss: 1.055, Acc: 61.19% F1(macro): 0.42: : 168it [00:21,  6.61it/s]
 Val:       Loss: 1.054, Acc: 61.18% F1(macro): 0.47: : 178it [00:24,  4.78it/s]
 Val:       Loss: 1.068, Acc: 60.56% F1(macro): 0.49: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.33it/s]
 Val:       Loss: 1.068, Acc: 60.56% F1(macro): 0.49: 100%|███████████████████████████████████████████████████████████████| 163/163 [00:25<00:00,  6.33it/s]
Train: [050] Loss: 1.253, Acc: 51.88% F1(macro): 0.33:   3%|██▏                                                            | 17/488 [00:01<00:36, 13.06it/s]
Train: [050] Loss: 1.262, Acc: 51.95% F1(macro): 0.36:   9%|█████▋                                                         | 44/488 [00:03<00:24, 17.90it/s]
Train: [050] Loss: 1.243, Acc: 54.08% F1(macro): 0.37:  13%|████████▏                                                      | 63/488 [00:05<00:34, 12.27it/s]
Train: [050] Loss: 1.234, Acc: 53.48% F1(macro): 0.36:  18%|███████████▎                                                   | 88/488 [00:07<00:25, 15.88it/s]
Train: [050] Loss: 1.237, Acc: 53.44% F1(macro): 0.36:  22%|█████████████▋                                                | 108/488 [00:09<00:26, 14.55it/s]
Train: [050] Loss: 1.243, Acc: 53.12% F1(macro): 0.36:  27%|████████████████▋                                             | 131/488 [00:11<00:21, 16.90it/s]
Train: [050] Loss: 1.236, Acc: 53.47% F1(macro): 0.36:  31%|███████████████████▏                                          | 151/488 [00:13<00:22, 14.86it/s]
Train: [050] Loss: 1.234, Acc: 53.63% F1(macro): 0.36:  34%|████████████████████▉                                         | 165/488 [00:15<00:46,  6.93it/s]
Train: [050] Loss: 1.237, Acc: 53.41% F1(macro): 0.37:  39%|████████████████████████▏                                     | 190/488 [00:17<00:25, 11.68it/s]
Train: [050] Loss: 1.230, Acc: 53.55% F1(macro): 0.37:  43%|██████████████████████████▋                                   | 210/488 [00:20<00:28,  9.81it/s]
Train: [050] Loss: 1.234, Acc: 53.48% F1(macro): 0.37:  48%|█████████████████████████████▋                                | 234/488 [00:21<00:17, 14.74it/s]
Train: [050] Loss: 1.232, Acc: 53.61% F1(macro): 0.37:  51%|███████████████████████████████▊                              | 250/488 [00:23<00:20, 11.82it/s]
Train: [050] Loss: 1.229, Acc: 53.73% F1(macro): 0.37:  56%|██████████████████████████████████▍                           | 271/488 [00:26<00:15, 14.45it/s]
Train: [050] Loss: 1.230, Acc: 53.81% F1(macro): 0.37:  59%|████████████████████████████████████▊                         | 290/488 [00:28<00:16, 11.91it/s]
Train: [050] Loss: 1.230, Acc: 53.84% F1(macro): 0.37:  62%|██████████████████████████████████████▌                       | 304/488 [00:29<00:11, 16.52it/s]
Train: [050] Loss: 1.230, Acc: 53.92% F1(macro): 0.37:  67%|█████████████████████████████████████████▍                    | 326/488 [00:31<00:15, 10.69it/s]
Train: [050] Loss: 1.235, Acc: 53.62% F1(macro): 0.36:  72%|████████████████████████████████████████████▎                 | 349/488 [00:33<00:12, 10.88it/s]
Train: [050] Loss: 1.233, Acc: 53.72% F1(macro): 0.37:  74%|██████████████████████████████████████████████                | 363/488 [00:35<00:13,  9.54it/s]
Train: [050] Loss: 1.230, Acc: 53.94% F1(macro): 0.37:  79%|████████████████████████████████████████████████▉             | 385/488 [00:37<00:07, 14.28it/s]
Train: [050] Loss: 1.231, Acc: 53.85% F1(macro): 0.37:  83%|███████████████████████████████████████████████████▍          | 405/488 [00:39<00:05, 13.88it/s]
Train: [050] Loss: 1.233, Acc: 53.80% F1(macro): 0.37:  88%|██████████████████████████████████████████████████████▍       | 428/488 [00:41<00:05, 10.71it/s]
Train: [050] Loss: 1.236, Acc: 53.68% F1(macro): 0.37:  91%|████████████████████████████████████████████████████████▋     | 446/488 [00:43<00:03, 11.46it/s]
Train: [050] Loss: 1.239, Acc: 53.63% F1(macro): 0.37:  96%|███████████████████████████████████████████████████████████▌  | 469/488 [00:45<00:01, 10.86it/s]
Train: [050] Loss: 1.238, Acc: 53.67% F1(macro): 0.37: 100%|█████████████████████████████████████████████████████████████▊| 487/488 [00:47<00:00,  9.96it/s]
Train: [050] Loss: 1.234, Acc: 53.88% F1(macro): 0.37: : 510it [00:49, 12.82it/s]
Train: [050] Loss: 1.234, Acc: 53.84% F1(macro): 0.37: : 522it [00:51,  5.37it/s]
  0%|                                                                                                                               | 0/163 [00:00<?, ?it/s]
 Val:       Loss: 1.895, Acc: 27.19% F1(macro): 0.07:  10%|██████▎                                                         | 16/163 [00:02<00:24,  6.03it/s]
 Val:       Loss: 1.372, Acc: 49.85% F1(macro): 0.19:  18%|███████████▍                                                    | 29/163 [00:04<00:20,  6.57it/s]
 Val:       Loss: 1.037, Acc: 65.17% F1(macro): 0.21:  32%|████████████████████▍                                           | 52/163 [00:06<00:10, 10.47it/s]
 Val:       Loss: 0.931, Acc: 69.63% F1(macro): 0.21:  43%|███████████████████████████▍                                    | 70/163 [00:08<00:10,  8.51it/s]
 Val:       Loss: 1.005, Acc: 66.73% F1(macro): 0.27:  51%|████████████████████████████████▌                               | 83/163 [00:10<00:09,  8.56it/s]
 Val:       Loss: 1.138, Acc: 58.03% F1(macro): 0.31:  63%|███████████████████████████████████████▍                       | 102/163 [00:12<00:06,  9.39it/s]
 Val:       Loss: 1.200, Acc: 53.09% F1(macro): 0.31:  73%|█████████████████████████████████████████████▉                 | 119/163 [00:14<00:03, 12.05it/s]
 Val:       Loss: 1.150, Acc: 56.14% F1(macro): 0.39:  81%|███████████████████████████████████████████████████            | 132/163 [00:16<00:04,  7.03it/s]
 Val:       Loss: 1.105, Acc: 58.48% F1(macro): 0.41:  89%|████████████████████████████████████████████████████████       | 145/163 [00:18<00:02,  6.01it/s]
 Val:       Loss: 1.077, Acc: 60.00% F1(macro): 0.41:  96%|████████████████████████████████████████████████████████████▎  | 156/163 [00:20<00:01,  6.22it/s]
 Val:       Loss: 1.040, Acc: 61.88% F1(macro): 0.42: : 172it [00:22,  6.11it/s]
 Val:       Loss: 1.053, Acc: 61.10% F1(macro): 0.46: : 177it [00:24,  4.93it/s]
  0%|                                                                                                                               | 0/163 [00:00<?, ?it/s]
 Val:       Loss: 1.885, Acc: 27.56% F1(macro): 0.07:  11%|███████                                                         | 18/163 [00:02<00:15,  9.17it/s]
 Val:       Loss: 1.372, Acc: 49.85% F1(macro): 0.19:  18%|███████████▍                                                    | 29/163 [00:04<00:19,  6.78it/s]
 Val:       Loss: 1.037, Acc: 65.17% F1(macro): 0.21:  32%|████████████████████▍                                           | 52/163 [00:06<00:11,  9.91it/s]
 Val:       Loss: 0.931, Acc: 69.63% F1(macro): 0.21:  44%|███████████████████████████▉                                    | 71/163 [00:08<00:10,  8.48it/s]
 Val:       Loss: 1.005, Acc: 66.73% F1(macro): 0.27:  51%|████████████████████████████████▌                               | 83/163 [00:10<00:09,  8.50it/s]
 Val:       Loss: 1.138, Acc: 58.03% F1(macro): 0.31:  63%|███████████████████████████████████████▊                       | 103/163 [00:12<00:05, 10.19it/s]
 Val:       Loss: 1.200, Acc: 53.09% F1(macro): 0.31:  73%|█████████████████████████████████████████████▉                 | 119/163 [00:14<00:04, 10.64it/s]
 Val:       Loss: 1.150, Acc: 56.14% F1(macro): 0.39:  81%|███████████████████████████████████████████████████            | 132/163 [00:16<00:04,  7.27it/s]
 Val:       Loss: 1.105, Acc: 58.48% F1(macro): 0.41:  89%|████████████████████████████████████████████████████████       | 145/163 [00:18<00:02,  6.12it/s]
 Val:       Loss: 1.077, Acc: 60.00% F1(macro): 0.41:  96%|████████████████████████████████████████████████████████████▎  | 156/163 [00:20<00:01,  6.25it/s]
 Val:       Loss: 1.040, Acc: 61.88% F1(macro): 0.42: : 172it [00:22,  6.01it/s]
 Val:       Loss: 1.053, Acc: 61.10% F1(macro): 0.46: : 177it [00:24,  4.87it/s]
RuntimeError: A single direction cannot be retrieved from a multi-objective study. Consider using Study.directions to retrieve a list containing all directions.iple': 0.75, 'm1': 'Conv', 'm1/repeat': 3, 'm1/out_channels': 16, 'm1/stride': 1, 'm1/activation': 'ReLU', 'm2': 'Pass', 'm2/repeat': 1, 'm2/out_channels': 16, 'm2/stride': 1, 'm3': 'InvertedResidualv2', 'm3/repeat': 2, 'm3/stride': 2, 'm3/v2_c': 16, 'm3/v2_t': 3, 'm4': 'InvertedResidualv2', 'm4/repeat': 4, 'm4/stride': 1, 'm4/v2_c': 32, 'm4/v2_t': 2, 'm5': 'Conv', 'm5/repeat': 1, 'm5/out_channels': 144, 'm5/kernel_size': 1, 'm5/activation': 'Hardswish', 'm5/stride': 2, 'm6': 'InvertedResidualv2', 'm6/repeat': 4, 'm6/stride': 2, 'm6/v2_c': 96, 'm6/v2_t': 1, 'm7': 'InvertedResidualv3', 'm7/repeat': 3, 'm7/stride': 1, 'm7/kernel_size': 5, 'm7/v3_t': 1.3, 'm7/v3_c': 152, 'm7/v3_se': 0, 'm7/v3_hs': 1, 'last_dim': 128, 'epochs': 50, 'img_size': 112, 'n_select': 6, 'batch_size': 32}.
RuntimeError: A single direction cannot be retrieved from a multi-objective study. Consider using Study.directions to retrieve a list containing all directions.iple': 0.75, 'm1': 'Conv', 'm1/repeat': 3, 'm1/out_channels': 16, 'm1/stride': 1, 'm1/activation': 'ReLU', 'm2': 'Pass', 'm2/repeat': 1, 'm2/out_channels': 16, 'm2/stride': 1, 'm3': 'InvertedResidualv2', 'm3/repeat': 2, 'm3/stride': 2, 'm3/v2_c': 16, 'm3/v2_t': 3, 'm4': 'InvertedResidualv2', 'm4/repeat': 4, 'm4/stride': 1, 'm4/v2_c': 32, 'm4/v2_t': 2, 'm5': 'Conv', 'm5/repeat': 1, 'm5/out_channels': 144, 'm5/kernel_size': 1, 'm5/activation': 'Hardswish', 'm5/stride': 2, 'm6': 'InvertedResidualv2', 'm6/repeat': 4, 'm6/stride': 2, 'm6/v2_c': 96, 'm6/v2_t': 1, 'm7': 'InvertedResidualv3', 'm7/repeat': 3, 'm7/stride': 1, 'm7/kernel_size': 5, 'm7/v3_t': 1.3, 'm7/v3_c': 152, 'm7/v3_se': 0, 'm7/v3_hs': 1, 'last_dim': 128, 'epochs': 50, 'img_size': 112, 'n_select': 6, 'batch_size': 32}.
layer                                     name  gradient   parameters                shape         mu      sigma
    0                    model.0.0.conv.weight      True          432        [16, 3, 3, 3]      0.029      0.458
    1                      model.0.0.bn.weight      True           16                 [16]        1.2      0.248
    2                        model.0.0.bn.bias      True           16                 [16]      0.251      0.669
    3                    model.0.1.conv.weight      True         2304       [16, 16, 3, 3]     0.0064        0.2
    4                      model.0.1.bn.weight      True           16                 [16]       1.23      0.288
    5                        model.0.1.bn.bias      True           16                 [16]       0.13      0.541
    6                model.1.0.conv.0.0.weight      True          768       [48, 16, 1, 1]   -0.00754      0.328
    7                model.1.0.conv.0.1.weight      True           48                 [48]          1       0.13
    8                  model.1.0.conv.0.1.bias      True           48                 [48]     0.0542      0.396
    9                model.1.0.conv.1.0.weight      True          432        [48, 1, 3, 3]    -0.0172      0.367
   10                model.1.0.conv.1.1.weight      True           48                 [48]       1.06      0.229
   11                  model.1.0.conv.1.1.bias      True           48                 [48]      0.145      0.364
   12                  model.1.0.conv.2.weight      True          768       [16, 48, 1, 1]   -0.00166      0.273
   13                  model.1.0.conv.3.weight      True           16                 [16]        1.1      0.267
   14                    model.1.0.conv.3.bias      True           16                 [16]   8.73e-08   6.69e-07
   15                model.1.1.conv.0.0.weight      True          768       [48, 16, 1, 1]   -0.00133      0.233
   16                model.1.1.conv.0.1.weight      True           48                 [48]      0.997     0.0487
   17                  model.1.1.conv.0.1.bias      True           48                 [48]     0.0827      0.273
   18                model.1.1.conv.1.0.weight      True          432        [48, 1, 3, 3]   -0.00174      0.351
   19                model.1.1.conv.1.1.weight      True           48                 [48]       1.01      0.224
   20                  model.1.1.conv.1.1.bias      True           48                 [48]     0.0379      0.305
   21                  model.1.1.conv.2.weight      True          768       [16, 48, 1, 1]     0.0191      0.218
   22                  model.1.1.conv.3.weight      True           16                 [16]       1.02      0.285
   23                    model.1.1.conv.3.bias      True           16                 [16]  -4.83e-08   1.94e-07
   24                model.2.0.conv.0.0.weight      True          512       [32, 16, 1, 1]     -0.011      0.342
   25                model.2.0.conv.0.1.weight      True           32                 [32]       1.04      0.141
   26                  model.2.0.conv.0.1.bias      True           32                 [32]      0.127      0.357
   27                model.2.0.conv.1.0.weight      True          288        [32, 1, 3, 3]   -0.00185      0.447
   28                model.2.0.conv.1.1.weight      True           32                 [32]       1.08      0.261
   29                  model.2.0.conv.1.1.bias      True           32                 [32]      0.254      0.463
   30                  model.2.0.conv.2.weight      True          768       [24, 32, 1, 1]    -0.0185      0.311
   31                  model.2.0.conv.3.weight      True           24                 [24]       1.05      0.277
   32                    model.2.0.conv.3.bias      True           24                 [24]   5.45e-08   2.09e-07
   33                model.2.1.conv.0.0.weight      True         1152       [48, 24, 1, 1]   0.000759      0.244
   34                model.2.1.conv.0.1.weight      True           48                 [48]          1     0.0556
   35                  model.2.1.conv.0.1.bias      True           48                 [48]      0.058      0.297
   36                model.2.1.conv.1.0.weight      True          432        [48, 1, 3, 3]    -0.0372      0.418
   37                model.2.1.conv.1.1.weight      True           48                 [48]       1.04      0.153
   38                  model.2.1.conv.1.1.bias      True           48                 [48]     -0.162      0.232
   39                  model.2.1.conv.2.weight      True         1152       [24, 48, 1, 1]    0.00583      0.245
   40                  model.2.1.conv.3.weight      True           24                 [24]      0.864       0.23
   41                    model.2.1.conv.3.bias      True           24                 [24]   3.06e-08   1.18e-07
   42                model.2.2.conv.0.0.weight      True         1152       [48, 24, 1, 1]     0.0265      0.255
   43                model.2.2.conv.0.1.weight      True           48                 [48]          1     0.0533
   44                  model.2.2.conv.0.1.bias      True           48                 [48]     -0.037      0.257
   45                model.2.2.conv.1.0.weight      True          432        [48, 1, 3, 3]    0.00474      0.355
   46                model.2.2.conv.1.1.weight      True           48                 [48]       1.02       0.17
   47                  model.2.2.conv.1.1.bias      True           48                 [48]     -0.106      0.229
   48                  model.2.2.conv.2.weight      True         1152       [24, 48, 1, 1]    0.00392      0.219
   49                  model.2.2.conv.3.weight      True           24                 [24]       1.23      0.201
   50                    model.2.2.conv.3.bias      True           24                 [24]  -1.43e-08   1.26e-07
   51                      model.3.conv.weight      True         2688      [112, 24, 1, 1]    0.00701      0.215
   52                        model.3.bn.weight      True          112                [112]          1      0.117
   53                          model.3.bn.bias      True          112                [112]     0.0171      0.116
   54                model.4.0.conv.0.0.weight      True         1008       [112, 1, 3, 3]    -0.0272      0.293
   55                model.4.0.conv.0.1.weight      True          112                [112]       1.01       0.17
   56                  model.4.0.conv.0.1.bias      True          112                [112]   -0.00265      0.163
   57                  model.4.0.conv.1.weight      True         8064      [72, 112, 1, 1]    0.00203      0.141
   58                  model.4.0.conv.2.weight      True           72                 [72]       1.11      0.119
   59                    model.4.0.conv.2.bias      True           72                 [72]    -0.0348      0.163
   60                model.4.1.conv.0.0.weight      True          648        [72, 1, 3, 3]    5.7e-05      0.306
   61                model.4.1.conv.0.1.weight      True           72                 [72]       1.01      0.125
   62                  model.4.1.conv.0.1.bias      True           72                 [72]    -0.0906      0.123
   63                  model.4.1.conv.1.weight      True         5184       [72, 72, 1, 1]  -0.000438      0.138
   64                  model.4.1.conv.2.weight      True           72                 [72]      0.951     0.0915
   65                    model.4.1.conv.2.bias      True           72                 [72]    -0.0133     0.0591
   66                model.4.2.conv.0.0.weight      True          648        [72, 1, 3, 3]    0.00193      0.272
   67                model.4.2.conv.0.1.weight      True           72                 [72]       1.01     0.0996
   68                  model.4.2.conv.0.1.bias      True           72                 [72]    -0.0695     0.0946
   69                  model.4.2.conv.1.weight      True         5184       [72, 72, 1, 1]   0.000551      0.117
   70                  model.4.2.conv.2.weight      True           72                 [72]      0.923      0.108
   71                    model.4.2.conv.2.bias      True           72                 [72]   1.64e-09    2.1e-08
   72                  model.5.0.conv.0.weight      True         6912       [96, 72, 1, 1]   -0.00222      0.136
   73                  model.5.0.conv.1.weight      True           96                 [96]       1.05      0.111
   74                    model.5.0.conv.1.bias      True           96                 [96]    -0.0353      0.124
   75                  model.5.0.conv.3.weight      True         2400        [96, 1, 5, 5]    -0.0227      0.192
   76                  model.5.0.conv.4.weight      True           96                 [96]       1.12       0.16
   77                    model.5.0.conv.4.bias      True           96                 [96]    -0.0545     0.0721
   78                  model.5.0.conv.7.weight      True        10752      [112, 96, 1, 1]    0.00143     0.0994
   79                  model.5.0.conv.8.weight      True          112                [112]       1.06     0.0543
   80                    model.5.0.conv.8.bias      True          112                [112]   1.19e-09   1.48e-08
   81                  model.5.1.conv.0.weight      True        16128     [144, 112, 1, 1]  -0.000662     0.0757
   82                  model.5.1.conv.1.weight      True          144                [144]       1.01     0.0384
   83                    model.5.1.conv.1.bias      True          144                [144]    -0.0118     0.0334
   84                  model.5.1.conv.3.weight      True         3600       [144, 1, 5, 5]    -0.0172      0.139
   85                  model.5.1.conv.4.weight      True          144                [144]       1.01     0.0996
   86                    model.5.1.conv.4.bias      True          144                [144]    -0.0209     0.0358
   87                  model.5.1.conv.7.weight      True        16128     [112, 144, 1, 1]   0.000548     0.0674
   88                  model.5.1.conv.8.weight      True          112                [112]      0.938     0.0546
   89                    model.5.1.conv.8.bias      True          112                [112]   7.28e-10   1.05e-08
   90                      model.6.conv.weight      True        10752      [96, 112, 1, 1]   0.000785     0.0823
   91                        model.6.bn.weight      True           96                 [96]       1.01     0.0786
   92                          model.6.bn.bias      True           96                 [96]    -0.0325     0.0642
   93                      model.8.conv.weight      True          576        [6, 96, 1, 1]    0.00347      0.282
   94                        model.8.bn.weight      True            6                  [6]       1.07      0.394
   95                          model.8.bn.bias      True            6                  [6]   1.44e-05      0.816
Model Summary: 134 layers, 108,332 parameters, 108,332 gradients
RuntimeError: A single direction cannot be retrieved from a multi-objective study. Consider using Study.directions to retrieve a list containing all directions.iple': 0.75, 'm1': 'Conv', 'm1/repeat': 3, 'm1/out_channels': 16, 'm1/stride': 1, 'm1/activation': 'ReLU', 'm2': 'Pass', 'm2/repeat': 1, 'm2/out_channels': 16, 'm2/stride': 1, 'm3': 'InvertedResidualv2', 'm3/repeat': 2, 'm3/stride': 2, 'm3/v2_c': 16, 'm3/v2_t': 3, 'm4': 'InvertedResidualv2', 'm4/repeat': 4, 'm4/stride': 1, 'm4/v2_c': 32, 'm4/v2_t': 2, 'm5': 'Conv', 'm5/repeat': 1, 'm5/out_channels': 144, 'm5/kernel_size': 1, 'm5/activation': 'Hardswish', 'm5/stride': 2, 'm6': 'InvertedResidualv2', 'm6/repeat': 4, 'm6/stride': 2, 'm6/v2_c': 96, 'm6/v2_t': 1, 'm7': 'InvertedResidualv3', 'm7/repeat': 3, 'm7/stride': 1, 'm7/kernel_size': 5, 'm7/v3_t': 1.3, 'm7/v3_c': 152, 'm7/v3_se': 0, 'm7/v3_hs': 1, 'last_dim': 128, 'epochs': 50, 'img_size': 112, 'n_select': 6, 'batch_size': 32}.