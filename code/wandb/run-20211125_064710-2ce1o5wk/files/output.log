idx |   n |     params |          module |            arguments |   in_channel |   out_channel
----------------------------------------------------------------------------------------------
  0 |   1 |     14,304 |            Conv |      [96, 7, 2, [0]] |            3           96
  1 |   1 |          0 |         MaxPool |         [3, 2, True] |           96           96
  2 |   1 |     11,920 |            Fire |         [16, 64, 64] |           96          128
  3 |   1 |     12,432 |            Fire |         [16, 64, 64] |          128          128
  4 |   1 |     45,344 |            Fire |       [32, 128, 128] |          128          256
  5 |   1 |          0 |         MaxPool |         [3, 2, True] |          256          256
  6 |   1 |     49,440 |            Fire |       [32, 128, 128] |          256          256
  7 |   1 |    104,880 |            Fire |       [48, 192, 192] |          256          384
  8 |   1 |    111,024 |            Fire |       [48, 192, 192] |          384          384
  9 |   1 |    188,992 |            Fire |       [64, 256, 256] |          384          512
 10 |   1 |          0 |         MaxPool |         [3, 2, True] |          512          512
 11 |   1 |    197,184 |            Fire |       [64, 256, 256] |          512          512
 12 |   1 |          0 |         Dropout |                [0.5] |          512          512
 13 |   1 |    514,000 |       FixedConv |         [1000, 1, 1] |          512         1000
 14 |   1 |          0 |   GlobalAvgPool |                   [] |         1000         1000
Model Summary: 70 layers, 1,249,520 parameters, 1,249,520 gradients
Model save path: exp/latest/best.pt
  0%|                                                                                                              | 0/244 [00:00<?, ?it/s]/opt/conda/envs/lightweight/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)










































Train: [001] Loss: 6.787, Acc: 17.08% F1(macro): 0.10: 100%|█████████████████████████████████████████████| 244/244 [01:44<00:00,  2.34it/s]

















 Val:       Loss: 6.506, Acc: 31.41% F1(macro): 0.08: : 95it [00:38,  2.95it/s]
 Val:       Loss: 6.514, Acc: 30.86% F1(macro): 0.08: 100%|████████████████████████████████████████████████| 82/82 [00:40<00:00,  2.04it/s]




































Train: [002] Loss: 6.032, Acc: 31.22% F1(macro): 0.13: 100%|█████████████████████████████████████████████| 244/244 [01:41<00:00,  2.41it/s]



















 Val:       Loss: 4.970, Acc: 32.90% F1(macro): 0.08: : 88it [00:39,  2.91it/s]

 Val:       Loss: 5.084, Acc: 31.20% F1(macro): 0.08: 100%|████████████████████████████████████████████████| 82/82 [00:42<00:00,  1.91it/s]



































Train: [003] Loss: 4.487, Acc: 31.05% F1(macro): 0.13:  78%|███████████████████████████████████          | 190/244 [01:17<00:22,  2.44it/s]
Traceback (most recent call last):
  File "train.py", line 138, in <module>
    device=device,
  File "train.py", line 89, in train
    val_dataloader=val_dl if val_dl else test_dl,
  File "/opt/ml/code/src/trainer.py", line 168, in train
    f"Train: [{epoch + 1:03d}] "
  File "/opt/conda/envs/lightweight/lib/python3.7/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/opt/conda/envs/lightweight/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1071, in f1_score
    zero_division=zero_division)
  File "/opt/conda/envs/lightweight/lib/python3.7/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/opt/conda/envs/lightweight/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1199, in fbeta_score
    zero_division=zero_division)
  File "/opt/conda/envs/lightweight/lib/python3.7/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/opt/conda/envs/lightweight/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1535, in precision_recall_fscore_support
    precision = np.average(precision, weights=weights)
  File "<__array_function__ internals>", line 6, in average
  File "/opt/conda/envs/lightweight/lib/python3.7/site-packages/numpy/lib/function_base.py", line 280, in average
    @array_function_dispatch(_average_dispatcher)
